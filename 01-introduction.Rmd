---
site: "bookdown::bookdown_site"
output:
  bookdown::gitbook: default
documentclass: book
#bibliography: ["book.bib", "packages.bib"]
biblio-style: apalike
link-citations: yes
---

# Introduction

Forecasting is a common practice to __predict future values given historical data__. 
It can be used to predict sales, expenses, web traffic, gross domestic product and 
other economic indicators, product usage, and so on.

Producing forecasts for univariate data is easy with off-the-shelf forecasting tools.
Tableau's [Forecast tool](https://help.tableau.com/current/pro/desktop/en-us/forecasting.htm) 
is a common one, although there are other tools in commercial software like 
Excel's [`FORECAST()` function](https://support.microsoft.com/en-us/office/forecast-and-forecast-linear-functions-50ca49c9-7b40-4892-94e4-7ad38bbeda99), and [Power BI's ARIMA extension](https://appsource.microsoft.com/en-us/product/power-bi-visuals/wa104380888?tab=overview). 

![](media/tableau_forecast_example.png)

While these are simple (and usually pretty effective for simple forecasts), sometimes they 
don't fit our modeling scenario or just fall short, like our good friend in the figure above. 

It helps to know how to generate a forecast with open-source _(free!)_ tools, 
since the models in commercial software are usually based on a common statistical models available in R.
It also pays off to __know some alternative models__ and additional tools that 
could improve the accuracy of the information being provided to stakeholders.

This guide is meant to show the most simple way to go form an off-the-shelf tool
to a state-of-the-art* forecast in 1 hour*.

## What is time series data?


Time series data is __data that is indexed by some time measurement__. As an Excel
sheet or a table, it looks like a table with a column for the time and a column
for the values of something at that time. Here is an example of the Dow Jones Industrial
Average (DJIA) __closing prices__:

```{r, echo=FALSE, message=F, warning=F}
library(astsa)
library(zoo)
library(forecast)
library(ggplot2)
library(knitr)
library(gridExtra)
```

```{r, echo=FALSE}
djia_df <- data.frame(Day=time(djia), Close=coredata(djia$Close))
knitr::kable(head(djia_df), booktabs=TRUE,
             caption="Daily DJIA values from 2006-2016.")
```

And here are the __quarterly earnings per share__ for Johnson & Johnson:

```{r, echo=FALSE}
jj_df <- data.frame(Quarter=time(jj), Earnings=coredata(jj))
knitr::kable(head(jj_df), booktabs=TRUE,
             caption="Johnson & Johnson quarterly earnings per share")
```

#### Multivariate Time Series Data {-}

The examples up to this point were examples of univariate time series data. __Multivariate__ time series
have a time column, and multiple measurements (additional columns) for a given time. 
Here is a multivariate time series of the seasonally adjusted, quarterly growth rate of
U.S. unemployment, GNP, consumption,and government and private investments from 1948 to 1988. 

```{r, echo=FALSE}
econ_ts <- ts(econ5, start=1948, frequency=4)
econ_data <- (econ5)
econ_data$time <- time(econ_ts)
econ_data <- econ_data[, c("time", "unemp", "gnp", "consum", "govinv", "prinv")]

unemp_ts <- diff(log(ts(econ_data$unemp, start=1948, freq=4))) * 100
gnp_ts <- diff(log(ts(econ_data$gnp, start=1948, freq=4))) * 100
consum_ts <- diff(log(ts(econ_data$consum, start=1948, freq=4))) * 100
govinv_ts <- diff(log(ts(econ_data$govinv, start=1948, freq=4))) * 100
prinv_ts <- diff(log(ts(econ_data$prinv, start=1948, freq=4))) * 100

econ_data <- econ_data[-1,]
econ_data$unemp <- unemp_ts %>% coredata() %>% round(2)
econ_data$gnp <- gnp_ts %>% coredata() %>% round(2)
econ_data$consum <- consum_ts %>% coredata() %>% round(2)
econ_data$govinv <- govinv_ts %>% coredata() %>% round(2)
econ_data$prinv <- prinv_ts %>% coredata() %>% round(2)

knitr::kable(
  head(econ_data), booktabs=TRUE,
  caption="Five economic growth factors (%) indexed by time."
)
```

#### Visualizing Multivariate Time Series Data {-}
Looking at each series in the context of the other helps identify visual patterns, 
such as the __spike__ in the unemployment growth rate in 1975 that led to a dip in GNP, 
consumption and private investment:

```{r, echo=FALSE}



fig_matrix <- rbind(c(1, 1), c(2, 3), c(4, 5))

p1 <- autoplot(unemp_ts) + ylab("Growth Rate (%)") + ggtitle("Unemployment")
p2 <- autoplot(gnp_ts) + ylab("Growth Rate (%)") + ggtitle("Gross National Product")
p3 <- autoplot(consum_ts) + ylab("Growth Rate (%)") + ggtitle("Consumption")
p4 <- autoplot(govinv_ts) + ylab("Growth Rate (%)") + ggtitle("Government Investment")
p5 <- autoplot(prinv_ts) + ylab("Growth Rate (%)") + ggtitle("Private Investment")

grid.arrange(p1, 
             arrangeGrob(p2, p3, ncol=2), 
             arrangeGrob(p4, p5, ncol=2), 
             nrow=3)
```


## Loading time series data into R

If you're new to R, you will first have to [install R and R Studio](https://www.earthdatascience.org/courses/earth-analytics/document-your-science/setup-r-rstudio/)
on your machine. You can even [change the R Studio theme](https://support.rstudio.com/hc/en-us/articles/115011846747-Using-RStudio-Themes) 
once it's installed if you're feeling fancy.

### Setting up the project

After everything is set up, open R Studio and __open a new R script__ under 
`File > New File > R Script`. This will open a blank file. First, save it under`File > Save` 
and save it in a new folder. Name the folder something useful, like `my_forecasting_project` or whatever 
will help keep things organized.

This will be __where you save any files related to your project__. It's good practice to
keep different types of files [in different folders](https://miro.medium.com/max/1340/1*CD3nTl6GEvTfbTMGB1_dFQ.png), but we'll use a simple, minimal folder structure that works for simple projects.

![](media/directory_example.png)


To make sure R Studio can easily find files in your current folder, go to 
`Session > Set Working Directory > To Source File Location`. This will __set your working directory__ 
as the folder that you created for the forecast script and data.

Finally, we need to install a few tools. In the [R Console](https://i1.wp.com/ikashnitsky.github.io/images/180522/layout-annotated.png?w=578&ssl=1), 
type the following:

```{r eval=FALSE}
install.packages("forecast")
install.packages("tidyverse")
install.packages("zoo")
install.packages("lubridate")
```

These contain the forecasting and time series tools that will speed up processing
data and generating forecasts.

### Loading the sample data

In your own project, ensure that your time series data is in a folder called `data` in the top of the project directory, so that the file structure looks like:

```
my_forecasting_project
│   my_forecasting_script.R
│
└───data
│   │   my_data.csv
│   │
```

We are now in R and have everything installed. Most scripting will happen in the 
[R source panel](https://i1.wp.com/ikashnitsky.github.io/images/180522/layout-annotated.png?w=578&ssl=1). 
In the source panel, type the following:

```{r, message=F, warning=F}
library(forecast)
library(tidyverse)
library(zoo)
library(lubridate)
```

and click `Run` in the top right-hand corner. Another option is select everything
in the script (`cmd+A` or `ctrl+A`) and then run it with `cmd + return` (or `ctrl + return`). If everything runs successfully, then you now have the functions loaded in your development environment to load the data.

Add the following lines under the previous lines of code to load the data and store it in a variable, `my_data`:

```{r, message=F, warning=F}
# load a csv from the data/ folder and store it as a dataframe
# the path relative to the current working directory
my_data <- read_csv('data/visitors.csv')
```

Now that the data is successfully loaded, we can look at the first few rows. After writing the next block, __move the cursor to the end of the line__, and hit `cmd+enter` to run that specific line. 

Going forward, use `cmd+enter` on the beginning of the line with the command that we want to execute to run each line of code.

```{r}
# view the first few lines of a dataframe
head(my_data)
```

These are standard steps across R workflows. Since we will be working with time
series data for forecasting, we will need to change the dataframe stored in
`my_data` to a `ts()` object. This is a special format that the `forecast` tools
understand.

```{r}
# convert dataframe to a weekly time series, starting 1/2014
my_ts <- ts(my_data$Visitors, start=2014, freq=52)
```

This step varies slightly depending on the time variable; this data is
weekly, but we can have monthly, quarterly, daily, annual, or even hourly data, which
requires a different value for `freq`. 

### Visualizing the sample data

To recap so far, this is how the `my_forecasting_script.R` file should look at this point:

```{r, eval=FALSE}
library(forecast)
library(tidyverse)
library(zoo)
library(lubridate)

# load a csv from the data/ folder and store it as a dataframe
# the path relative to the current working directory
my_data <- read_csv('data/visitors.csv')

# view the first few lines of a dataframe
head(my_data)

# convert dataframe to a weekly time series, starting 1/2014
my_ts <- ts(my_data$Visitors, start=2014, freq=52)
```

Now that the data is loaded and formatted, we can generate a quick visualization
using `autoplot()` function from the `forecast` package after the last line in the script:

```{r}
autoplot(my_ts) +
  ggtitle("My Time Series Plot")
```

The first line defines the base plot, and we add a title to it by adding `+` after 
the `autoplot()` function, moving to the next line for readability, and using the
`ggtitle()` function to add a title to it. This is `ggplot2` syntax. You can read
more about `ggplot2` at depth in [R for Data Science](https://r4ds.had.co.nz/). 

__That's it!__ You can start forecasting now. We will use this data to build a 
simple linear regression forecast in the next section, equivalent to the `FORECAST()` 
function in Excel.

## A simple forecast

Using linear regression for time series analysis might seem odd to some people, since time series 
data usually violates [linear regression assumptions](https://online.stat.psu.edu/stat462/node/189/), 
specifically regarding the issue of autocorrelated errors generated by the model. However this is a 
really easy way to __generate some prediction about future values__ using past data, 
so it's used anyway.

Our linear regression model predicts the value $y$, given some values $t$:

$$
y = \beta_0 + \beta_1t
$$

where $\beta_0$ is the intercept, and $\beta_1$ is the slope in our data. These quantities
are found by minimizing $(y - \hat{y})^2$, known as the squared error of the line and the data. This leads to a "best fit" straight line. 

If the statement above is unclear, don't fret. Just know that $\beta_0$ and $\beta_1$ are __found automatically based on our data__, and provide the __best line possible__ for our data (the line
with the smallest possible error between itself and the data points). 

The following R examples should be added to the `my_first_forecast.R` script following
the code from the previous section about loading the data into R. The same variable names will be used.


#### The Magic Sauce {-}

This is where we conjure some data entities. Usually we would use the `lm()` command in R (`lm()` stands for "linear model"), but there
is a function `tslm()` that is specifically for time series data. 

After fitting the model use `fitted()` to see what the model looks like against our data.

```{r}
# fit the model and store in a variable called my_model
my_model <- tslm(my_ts ~ trend) 

# provide the fitted values of the model
model_fit <- my_model %>% fitted()
```

`tslm(my_ts ~ trend)` means we want a linear model where `my_ts` is the dependent variable.
and `trend` is the independent variable, which indicates in this model that we want a 
__trend-only forecast__ (straight line). To add a seasonal linear regression component, use `tslm(my_ts ~ trend + season)`.
This example uses trend only first to demonstrate a simple forecast.

Now that we have a model, let's see how it looks compared to our data.

```{r}
autoplot(my_ts) +
  # autolayer() is used to add another time series to the plot
  autolayer(model_fit, color="red") +
  ggtitle("Linear Regession Fit") +
  xlab("Time") + 
  ylab("Unique Visitors")
```


We can now make a forecast for the next year using `forecast()`, and add the number
of time steps to predict.

```{r}
# predict the value of the new data 
next_years_visitors <- my_model %>% forecast(h=52) 
```

Let's visualize it with our historical data:

```{r}
autoplot(my_ts) +
  # the "series" argument labels the data in the legend
  autolayer(next_years_visitors, series="Forecast") +
  ggtitle("Linear Regession Forecast") +
  xlab("Time") + 
  ylab("Unique Visitors")
```

This is linear regression as a trend-only model (what is typically used in the `FORECAST()` function
in Excel). To get trend and __seasonality__:

```{r}
# fit a model with trend and season
seasonal_model <- tslm(my_ts ~ trend + season)

# forecast the next 52 weeks with the model
seasonal_forecast <- seasonal_model %>% forecast(h=52)
```

which produces the following trend:

```{r}
autoplot(my_ts) +
  autolayer(seasonal_forecast, series="Forecast") +
  ggtitle("Linear Regession with Seasonal Forecast") +
  xlab("Time") + 
  ylab("Unique Visitors")
```


To export the predictions as a `.csv`, write 

```{r eval=FALSE}
write.csv(seasonal_forecast, 'my_predictions.csv')
``` 

in the R Console. Change the `.csv` to any file name that makes sense.


## Forecast accuracy

![](media/zoltar.png)


_How accurate is this model?_

Forecasting is sometimes seen as magic. You put a coin in the machine and it prints
out a ticket with a prediction of the future.

While this isn't too far off from the reality of a data scientist, I would like to 
believe that data science is built on more than fortune telling; it's built on 
healthy skepticism, scientific rigor, and confusing branding.

So before providing a prediction about the future, remember that predictions about
the future are generated using a _model of the past_. If the future is expected
to look very different from the past, then the predictions of the future will
be _unreliable_.

For this reason, it's important to provide a measure of __model accuracy__.


### Evaluating the forecast in R

There are a few accuracy metrics for forecasting models, each with their strengths 
and weaknesses.The `forecast` package in R has simple implementations of evaluation metrics
to see how well the model fits the data, and how well it predicts a small, held-out sample of the
data. 

#### Linear regression evaluation {-}

To see how well a linear regression model fits our data, we split the data
into a training and test set. The __training set__ is used to build the linear
regression model, and the __test set__ is used to provide an accuracy metric to
judge the performance of the model on new data.


```{r}
train_data <- my_ts %>% window(end=decimal_date(ymd('2017-12-31')))
test_data <- my_ts %>% window(start=decimal_date(ymd('2018-01-01')))
```

The simplest error metric is __mean absolute error (MAE)__, which is found by subtracting the 
predicted value from the actual value at each time $t$, and then seeing what the average
error was, across all times. 

The downside of this accuracy measure is that it assumes __large errors and small errors are weighted equally__. This is why it's important to also visualize the model residuals to detect large errors or outliers. 

```{r}
autoplot(train_data, series="Training") +
  autolayer(test_data, series="Test") +
  guides(colour=guide_legend("Split")) +
  scale_color_manual(values=c("grey", "black")) +
  xlab("Time") +
  ylab("Unique Visitors") + 
  ggtitle("Train/Test Split: Weekly Data")
```

Now we calculate the test accuracy of the model after re-fitting on the training data
*only*. We can also visualize the model prediction to get an idea of how well the model
generalizes:

```{r}
# fit a model on the training data with trend and season
train_model <- tslm(train_data ~ trend + season)

# forecast the next 52 weeks with the model; forecast horizon matches the test data
train_forecast <- train_model %>% forecast(h=52)

# assess the model accuracy
accuracy(train_forecast, test_data)

# plot the predictions
autoplot(train_data, color="black") +
  autolayer(test_data, color="grey") +
  autolayer(train_forecast, PI=FALSE) +
  xlab("Time") + 
  ylab("Unique Visitors") +
  ggtitle("Linear Regression Forecast")
```


If we focus solely on __mean absolute error (MAE)__, we see that our model is off by about 11
visitors per week, on average. The quality of this model could be sufficient if it's only used
to help guide a judgmental forecast (one you come up with based on intuition),
but it could be insufficient if the forecast is a major input to a managerial decision. 

The rest of the guide is designed to demonstrate the tools for __providing more
accurate forecasts.__

#### Summary {-}

Those are _roughly_ the steps to produce a forecast in R:

1. Load data and convert it to a time series
2. Fit a model to training data
3. Evaluate the model on test data
4. Re-fit the model on the full data
5. Forecast the future

In practice, model evaluation (seeing how well it generalizes) and model interpretation are
crucial steps in the process that will require a bit more work. The steps up 
to this point illustrate __how to just do the thing in R__.


